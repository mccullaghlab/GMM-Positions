{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import MDAnalysis as md\n",
    "from MDAnalysis.analysis.rms import rmsd\n",
    "from MDAnalysis.analysis import align\n",
    "from shapeGMM import gmm_shapes\n",
    "import sys\n",
    "import pyemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of atoms in trajectory: 284\n",
      "Number of frames in trajectory: 20225\n",
      "Number of atoms in selection: 20\n"
     ]
    }
   ],
   "source": [
    "#load in Trp-cage trajectory data\n",
    "prmtopFileName = \"trp-cage-2jof_350K.run.3650000000.part0146.nowater.gro\"\n",
    "trajFileName = \"trp-cage-2jof_350K.stepid10150000000.every1ns.nowater.align.xtc\"\n",
    "\n",
    "coord = md.Universe(prmtopFileName,trajFileName)\n",
    "\n",
    "print(\"Number of atoms in trajectory:\", coord.atoms.n_atoms)\n",
    "print(\"Number of frames in trajectory:\", coord.trajectory.n_frames)\n",
    "# make atom selection\n",
    "CAatomSel = coord.select_atoms('name CA')\n",
    "print(\"Number of atoms in selection:\", CAatomSel.n_atoms)\n",
    "# create traj data of selection\n",
    "trajData = np.empty((coord.trajectory.n_frames,CAatomSel.n_atoms,3),dtype=float)\n",
    "\n",
    "#loop traj\n",
    "for ts in coord.trajectory:\n",
    "    trajData[ts.frame,:,:] = CAatomSel.positions - CAatomSel.center_of_geometry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Cluster Scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def weighted_cross_validate_cluster_scan(traj_data, n_train_frames, cluster_array = np.arange(2,9,1).astype(int), n_training_sets=10, n_attempts = 5):\n",
    "    \"\"\"\n",
    "    perform cross validation weighted shape-GMM for range of cluster sizes\n",
    "    Inputs:\n",
    "        traj_data                  (required)  : float64 array with dimensions (n_frames, n_atoms,3) of molecular configurations\n",
    "        n_train_frames             (required)  : int     scalar dictating number of frames to use as training (rest is used for CV)\n",
    "        cluster_array       (default: [2..8])  : int     array of cluster sizes - can be of any number but must be ints. Default is [2, 3, 4, 5, 6, 7, 8]\n",
    "        n_training_sets         (default: 10)  : int     scalar dictating how many training sets to choose. Default is 10\n",
    "        n_attempts               (default: 5)  : int     scalar dictating how many attempts to perform shape-GMM on same set.  Default is 5\n",
    "    Returns:\n",
    "        weighted_train_log_lik                 : float64 array with dimensions (n_clusters, n_training_sets) containing log likelihoods for each training set\n",
    "        weighted_predict_log_lik               : float64 array with dimensions (n_clusters, n_training_sets) containing log likelihoods on each CV set\n",
    "    \"\"\"\n",
    "    # meta data from input array\n",
    "    n_frames = traj_data.shape[0]\n",
    "    # set parameters\n",
    "    n_predict_frames = n_frames - n_train_frames\n",
    "    print(\"Number of frames to train each model:\", n_train_frames)\n",
    "    print(\"Number of frames to predict each model:\", n_predict_frames)\n",
    "    print(\"Number of training sets:\", n_training_sets)\n",
    "    print(\"Number of clusters:\", cluster_array.size)\n",
    "    print(\"Number of attempts per set/cluster:\", n_attempts)\n",
    "    sys.stdout.flush()\n",
    "    # open data files\n",
    "    weighted_train_log_lik = np.empty((cluster_array.size,n_training_sets),dtype=np.float64)\n",
    "    weighted_predict_log_lik = np.empty((cluster_array.size,n_training_sets),dtype=np.float64)\n",
    "    # print log info\n",
    "    print(\"%15s %15s %15s %19s %15s\" % (\"Training Set\", \"N Clusters\", \"Attempt\", \"Log Like per Frame\",\"CPU Time (s)\"))\n",
    "    print(\"%84s\" % (\"------------------------------------------------------------------------------------\"))\n",
    "    # loop over training sets\n",
    "    for training_set in range(n_training_sets):\n",
    "        # shuffle trajectory data\n",
    "        np.random.shuffle(traj_data)\n",
    "        # create training and predict data\n",
    "        train_data = traj_data[:n_train_frames]\n",
    "        predict_data = traj_data[n_train_frames:]\n",
    "        # loop over all number of clusters\n",
    "        for cluster_index, cluster_size in enumerate(cluster_array):\n",
    "            w_log_lik = []\n",
    "            w_objs = []\n",
    "            # for each n_clusters and training set, perform shape-GMM n_attempts times and take object with largest log likelihood\n",
    "            for attempt in range(n_attempts):\n",
    "                start_time = time.process_time()\n",
    "                wsgmm = gmm_shapes.ShapeGMM(cluster_size,kabsch_thresh=1e-1,init_cluster_method='random',init_iter=5)\n",
    "                wsgmm.fit_weighted(train_data)\n",
    "                w_log_lik.append(wsgmm.log_likelihood)\n",
    "                w_objs.append(wsgmm)\n",
    "                elapsed_time = time.process_time()-start_time\n",
    "                print(\"%15d %15d %15d %19.3f %15.3f\" % (training_set+1, cluster_size, attempt+1, np.round(wsgmm.log_likelihood/wsgmm.n_frames,3), np.round(elapsed_time,3)))\n",
    "            # determine maximum\n",
    "            w_arg = np.argmax(w_log_lik)\n",
    "            # save training log likes\n",
    "            weighted_train_log_lik[cluster_index,training_set] = w_log_lik[w_arg]\n",
    "            # save prediction log likes\n",
    "            weighted_predict_log_lik[cluster_index,training_set] = w_objs[w_arg].predict_weighted(predict_data)[2]\n",
    "\n",
    "    # convert to log likelihood per frame\n",
    "    weighted_train_log_lik /= n_train_frames\n",
    "    weighted_predict_log_lik /= n_predict_frames\n",
    "    #return\n",
    "    return weighted_train_log_lik, weighted_predict_log_lik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define cluster array\n",
    "cluster_array = np.arange(2,9,1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames to train each model: 1000\n",
      "Number of frames to predict each model: 19225\n",
      "Number of training sets: 5\n",
      "Number of clusters: 7\n",
      "Number of attempts per set/cluster: 10\n",
      "   Training Set      N Clusters         Attempt  Log Like per Frame    CPU Time (s)\n",
      "------------------------------------------------------------------------------------\n",
      "              1               2               1              10.656          34.938\n",
      "              1               2               2              10.656          10.292\n",
      "              1               2               3              10.798          10.992\n",
      "              1               2               4              10.656          12.478\n",
      "              1               2               5              10.656           9.168\n",
      "              1               2               6              10.656           9.040\n",
      "              1               2               7              10.656          10.500\n",
      "              1               2               8              10.656           9.896\n",
      "              1               2               9              10.656          11.940\n",
      "              1               2              10              10.656           8.918\n",
      "              1               3               1              13.529          10.364\n",
      "              1               3               2              13.529          14.807\n",
      "              1               3               3              14.248          17.303\n",
      "              1               3               4              14.248          21.386\n",
      "              1               3               5              14.248          18.808\n",
      "              1               3               6              14.248          20.619\n",
      "              1               3               7              12.897          11.061\n",
      "              1               3               8              13.529          15.363\n",
      "              1               3               9              14.248          23.102\n",
      "              1               3              10              13.529          13.437\n",
      "              1               4               1              14.815          27.963\n",
      "              1               4               2              15.612          44.055\n",
      "              1               4               3              15.027          25.112\n",
      "              1               4               4              14.638          32.860\n",
      "              1               4               5              14.078          27.146\n",
      "              1               4               6              15.615          34.493\n",
      "              1               4               7              15.613          34.642\n",
      "              1               4               8              15.613          38.077\n",
      "              1               4               9              14.757          21.309\n",
      "              1               4              10              14.713          29.617\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9d67da635ab2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run cluster CV scan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# NOTE: This will take a few hours\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweighted_train_log_lik\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_predict_log_lik\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_cross_validate_cluster_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrajData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcluster_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_training_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_attempts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-c31a7db326d2>\u001b[0m in \u001b[0;36mweighted_cross_validate_cluster_scan\u001b[0;34m(traj_data, n_train_frames, cluster_array, n_training_sets, n_attempts)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mwsgmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmm_shapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mShapeGMM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkabsch_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_cluster_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'random'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minit_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mwsgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mw_log_lik\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsgmm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0mw_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwsgmm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/shapeGMM-0.0.5-py3.8.egg/shapeGMM/gmm_shapes.py\u001b[0m in \u001b[0;36mfit_weighted\u001b[0;34m(self, traj_data, clusters)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_frame_ln_likelihoods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmm_shapes_weighted_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpectation_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlpdets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;31m# Maximum Likelihood Oprecisionptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlpdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_likelihoodArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgmm_shapes_weighted_library\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum_likelihood_opt_weighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_frame_ln_likelihoods\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraj_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlpdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkabsch_thresh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkabsch_max_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_likelihoodArray\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run cluster CV scan\n",
    "# NOTE: This will take a few hours\n",
    "weighted_train_log_lik, weighted_predict_log_lik = weighted_cross_validate_cluster_scan(trajData,1000,cluster_array = cluster_array, n_training_sets=5, n_attempts=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_train_filename=\"weighted_train_10K_2_8.dat\"\n",
    "weighted_predict_filename=\"weighted_train_10K_predict_2_8.dat\"\n",
    "# write to data files\n",
    "np.savetxt(weighted_train_filename,np.column_stack((cluster_array,weighted_train_log_lik)))\n",
    "np.savetxt(weighted_predict_filename,np.column_stack((cluster_array,weighted_predict_log_lik)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create figure\n",
    "plt.figure(figsize=(10,10), dpi= 120, facecolor='w', edgecolor='k')\n",
    "# Training\n",
    "weighted_train_mean = np.mean(weighted_train_log_lik,axis=1)\n",
    "weighted_train_std = np.std(weighted_train_log_lik,axis=1)\n",
    "plt.errorbar(cluster_array,weighted_train_mean,weighted_train_std,fmt='-o',lw=3,capsize=3,label=\"W-SGMM Training\")\n",
    "lower, upper = pyemma.util.statistics.confidence_interval((weighted_train_log_lik).T.tolist(), conf=0.9)\n",
    "plt.fill_between(cluster_array, lower, upper, alpha=0.3)\n",
    "# Cross Validation\n",
    "weighted_predict_mean = np.mean(weighted_predict_log_lik,axis=1)\n",
    "weighted_predict_std = np.std(weighted_predict_log_lik,axis=1)\n",
    "plt.errorbar(cluster_array,weighted_predict_mean,weighted_predict_std,fmt='--x',lw=3,capsize=3,label=\"W-SGMM Cross Validation\")\n",
    "lower, upper = pyemma.util.statistics.confidence_interval((weighted_predict_log_lik).T.tolist(), conf=0.9)\n",
    "plt.fill_between(cluster_array, lower, upper, alpha=0.3)\n",
    "# set some stuff for the plot\n",
    "plt.grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "plt.ylabel(\"Log Likelihood per Frame\",fontsize=16)\n",
    "plt.xlabel(\"Number of Clusters\",fontsize=16)\n",
    "plt.tick_params(axis='both',labelsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster again based on nClusters chosen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "objs = []\n",
    "log_likes = []\n",
    "for i in range(10):\n",
    "    wsgmm = gmm_shapes.ShapeGMM(n_clusters,kabsch_thresh=1e-1,init_cluster_method='random',init_iter=5)\n",
    "    wsgmm.fit_weighted(trajData[1::2])\n",
    "    print(i+1, wsgmm.log_likelihood/wsgmm.n_frames)\n",
    "    objs.append(wsgmm)\n",
    "    log_likes.append(wsgmm.log_likelihood)\n",
    "# select obj with max log likelihood per frame\n",
    "wsgmm = objs[np.argmax(log_likes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save object\n",
    "import pickle\n",
    "pickle.dump(wsgmm,open(\"trpcage_wsgmm_5_clusters.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on entire of trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters, aligned_traj, log_likelihood = wsgmm.predict_weighted(trajData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(clusters,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Clustering in 2D RMSD space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RMSD data of selections\n",
    "trajRMSD_hx = np.empty(coord.trajectory.n_frames-1,dtype=float)\n",
    "trajRMSD_3_10 = np.empty(coord.trajectory.n_frames-1,dtype=float)\n",
    "hx = coord.select_atoms(\"name CA and resid 2:9\")\n",
    "h_3_10 = coord.select_atoms(\"name CA and resid 11:15\")\n",
    "# make first frame the reference (arbitrary but there you have it)\n",
    "hx_ref = np.copy(hx.positions)\n",
    "h_3_10_ref = np.copy(h_3_10.positions)\n",
    "for ts in coord.trajectory[1::]:\n",
    "    trajRMSD_hx[ts.frame-1] = rmsd(hx.positions,hx_ref,superposition=True)\n",
    "    trajRMSD_3_10[ts.frame-1] = rmsd(h_3_10.positions,h_3_10_ref,superposition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data on LDA 1 and LDA 2 with points colored by cluster number\n",
    "import matplotlib.cm as cm\n",
    "plt.figure(figsize=(12, 12),dpi=300)\n",
    "plt.xlabel(\"Alpha Helix RMSD\",fontsize=20)\n",
    "plt.ylabel(\"3-10 Helix RMSD\",fontsize=20)\n",
    "x = trajRMSD_hx\n",
    "y = trajRMSD_3_10\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "plt.contour(xx,yy,H,cmap='binary')\n",
    "plt.tick_params(axis='both',labelsize=16)\n",
    "plt.grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "plt.scatter(trajRMSD_hx,trajRMSD_3_10,c=clusters[1:],alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Clustering in 2D Mahalanobis Distance Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapeGMM import _traj_tools_toolsj_tools as traj_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Maha Distance array\n",
    "traj_maha = np.empty((coord.trajectory.n_frames,wsgmm.n_clusters),dtype=float)\n",
    "for coord_frame in range(coord.trajectory.n_frames):\n",
    "    for cluster in range(wsgmm.n_clusters):\n",
    "        traj_maha[coord_frame,cluster] = np.sqrt(traj_tools.weight_kabsch_dist(trajData[coord_frame],wsgmm.centers[cluster],wsgmm.precisions[cluster]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data on LDA 1 and LDA 2 with points colored by cluster number\n",
    "import matplotlib.cm as cm\n",
    "plt.figure(figsize=(12, 12),dpi=300)\n",
    "plt.xlabel(\"Mahalanobis Distance to Cluster 1\",fontsize=20)\n",
    "plt.ylabel(\"Mahalanobis Distance to Cluster 3\",fontsize=20)\n",
    "x = traj_maha[:,0]\n",
    "y = traj_maha[:,2]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "plt.contour(xx,yy,H,cmap='binary')\n",
    "plt.tick_params(axis='both',labelsize=16)\n",
    "plt.grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "plt.scatter(traj_maha[:,0],traj_maha[:,2],c=clusters,alpha=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Align Trajectory in a Variety of Ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapeGMM import _traj_tools as traj_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with a global alignment of all frames using covariance weighted alignment (iterative)\n",
    "# NOTE: This will take ~30 seconds\n",
    "global_aligned_traj = traj_tools.traj_iterative_average_precision_weighted_kabsch(trajData)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align to cluster 1 (non-iterative)\n",
    "# NOTE: I have no idea which cluster is cluster 1\n",
    "cluster_1_aligned_traj = traj_tools.traj_align_weighted_kabsch(trajData,wsgmm.centers[0],wsgmm.precisions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align to cluster 2 (non-iterative)\n",
    "# NOTE: I have no idea which cluster is cluster 2\n",
    "cluster_2_aligned_traj = traj_tools.traj_align_weighted_kabsch(trajData,wsgmm.centers[1],wsgmm.precisions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align to cluster 3 (non-iterative)\n",
    "# NOTE: I have no idea which cluster is cluster 3\n",
    "cluster_3_aligned_traj = traj_tools.traj_align_weighted_kabsch(trajData,wsgmm.centers[2],wsgmm.precisions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align to cluster 4 (non-iterative)\n",
    "# NOTE: I have no idea which cluster is cluster 4\n",
    "cluster_4_aligned_traj = traj_tools.traj_align_weighted_kabsch(trajData,wsgmm.centers[3],wsgmm.precisions[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align to cluster 5 (non-iterative)\n",
    "# NOTE: I have no idea which cluster is cluster 5\n",
    "cluster_5_aligned_traj = traj_tools.traj_align_weighted_kabsch(trajData,wsgmm.centers[4],wsgmm.precisions[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12), dpi=120,sharey=True,sharex=True)\n",
    "# 00\n",
    "axes[0,0].set_title(\"Global Alignment\")\n",
    "axes[0,0].set_ylabel(\"Free Energy / kT\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_sgmm3 = lda.fit_transform(global_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_sgmm3[:,0],range=(-8,10),bins=50)[0])\n",
    "axes[0,0].tick_params(axis='both',labelsize=16)\n",
    "axes[0,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[0,0].plot(np.arange(-8,10,0.36),fe-np.amin(fe),lw=2)\n",
    "axes[0,0].set_ylim(0,7.5)\n",
    "axes[0,0].set_xlim(-10,3)\n",
    "# 01\n",
    "axes[0,1].set_title(\"Alignment to Cluster 1\")\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_1_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,0],range=(-8,10),bins=50)[0])\n",
    "axes[0,1].tick_params(axis='both',labelsize=16)\n",
    "axes[0,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[0,1].plot(-np.arange(-8,10,0.36),fe-np.amin(fe),lw=2)\n",
    "axes[0,1].set_ylim(0,7.5)\n",
    "axes[0,1].set_xlim(-10,3)\n",
    "# 10\n",
    "axes[1,0].set_title(\"Alignment to Cluster 2\")\n",
    "axes[1,0].set_ylabel(\"Free Energy / kT\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_2_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,0],range=(-8,10),bins=50)[0])\n",
    "axes[1,0].tick_params(axis='both',labelsize=16)\n",
    "axes[1,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[1,0].plot(np.arange(-8,10,0.36),fe-np.amin(fe),lw=2)\n",
    "axes[1,0].set_ylim(0,7.5)\n",
    "axes[1,0].set_xlim(-10,3)\n",
    "# 11\n",
    "axes[1,1].set_title(\"Alignment to Cluster 3\")\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_3_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,0],range=(-8,10),bins=50)[0])   # this one needs to be flipped\n",
    "axes[1,1].tick_params(axis='both',labelsize=16)\n",
    "axes[1,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[1,1].plot(-np.arange(-8,10,0.36),fe-np.amin(fe),lw=2)\n",
    "axes[1,1].set_ylim(0,7.5)\n",
    "axes[1,1].set_xlim(-10,3)\n",
    "# 20\n",
    "axes[2,0].set_title(\"Alignment to Cluster 4\")\n",
    "axes[2,0].set_xlabel(\"LD 1\",fontsize=16)\n",
    "axes[2,0].set_ylabel(\"Free Energy / kT\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_4_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,0],range=(-8,10),bins=50)[0])\n",
    "axes[2,0].tick_params(axis='both',labelsize=16)\n",
    "axes[2,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[2,0].plot(np.arange(-8,10,0.36),fe-np.amin(fe),lw=2)\n",
    "axes[2,0].set_ylim(0,7.5)\n",
    "axes[2,0].set_xlim(-10,3)\n",
    "# 21\n",
    "axes[2,1].set_title(\"Alignment to Cluster 5\")\n",
    "axes[2,1].set_xlabel(\"LD 1\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_5_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,0],range=(-8,10),bins=50)[0])   # this one needs to be flipped\n",
    "axes[2,1].tick_params(axis='both',labelsize=16)\n",
    "axes[2,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[2,1].plot(np.arange(-8,10,0.36),fe-np.amin(fe),lw=2)\n",
    "axes[2,1].set_ylim(0,7.5)\n",
    "axes[2,1].set_xlim(-10,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12), dpi=120,sharey=True,sharex=True)\n",
    "# 00\n",
    "axes[0,0].set_title(\"Global Alignment\")\n",
    "axes[0,0].set_ylabel(\"Free Energy / kT\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_sgmm3 = lda.fit_transform(global_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_sgmm3[:,1],range=(-3,3),bins=50)[0])\n",
    "axes[0,0].tick_params(axis='both',labelsize=16)\n",
    "axes[0,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[0,0].plot(np.arange(-3,3,0.12),fe-np.amin(fe),lw=2)\n",
    "axes[0,0].set_ylim(0,7.5)\n",
    "axes[0,0].set_xlim(-3,3)\n",
    "# 01\n",
    "axes[0,1].set_title(\"Alignment to Cluster 1\")\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_1_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,1],range=(-3,3),bins=50)[0])\n",
    "axes[0,1].tick_params(axis='both',labelsize=16)\n",
    "axes[0,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[0,1].plot(-np.arange(-3,3,0.12),fe-np.amin(fe),lw=2)\n",
    "axes[0,1].set_ylim(0,7.5)\n",
    "axes[0,1].set_xlim(-3,3)\n",
    "# 10\n",
    "axes[1,0].set_title(\"Alignment to Cluster 2\")\n",
    "axes[1,0].set_ylabel(\"Free Energy / kT\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_2_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,1],range=(-3,3),bins=50)[0])\n",
    "axes[1,0].tick_params(axis='both',labelsize=16)\n",
    "axes[1,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[1,0].plot(np.arange(-3,3,0.12),fe-np.amin(fe),lw=2)\n",
    "axes[1,0].set_ylim(0,7.5)\n",
    "axes[1,0].set_xlim(-3,3)\n",
    "# 11\n",
    "axes[1,1].set_title(\"Alignment to Cluster 3\")\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_3_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,1],range=(-3,3),bins=50)[0])   # this one needs to be flipped\n",
    "axes[1,1].tick_params(axis='both',labelsize=16)\n",
    "axes[1,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[1,1].plot(-np.arange(-3,3,0.12),fe-np.amin(fe),lw=2)\n",
    "axes[1,1].set_ylim(0,7.5)\n",
    "axes[1,1].set_xlim(-3,3)\n",
    "# 20\n",
    "axes[2,0].set_title(\"Alignment to Cluster 4\")\n",
    "axes[2,0].set_xlabel(\"LD 2\",fontsize=16)\n",
    "axes[2,0].set_ylabel(\"Free Energy / kT\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_4_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,1],range=(-3,3),bins=50)[0])\n",
    "axes[2,0].tick_params(axis='both',labelsize=16)\n",
    "axes[2,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[2,0].plot(np.arange(-3,3,0.12),fe-np.amin(fe),lw=2)\n",
    "axes[2,0].set_ylim(0,7.5)\n",
    "axes[2,0].set_xlim(-3,3)\n",
    "# 21\n",
    "axes[2,1].set_title(\"Alignment to Cluster 5\")\n",
    "axes[2,1].set_xlabel(\"LD 2\",fontsize=16)\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred_gmm3 = lda.fit_transform(cluster_5_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "fe = -np.log(np.histogram(y_pred_gmm3[:,1],range=(-3,3),bins=50)[0])   # this one needs to be flipped\n",
    "axes[2,1].tick_params(axis='both',labelsize=16)\n",
    "axes[2,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "axes[2,1].plot(np.arange(-3,3,0.12),fe-np.amin(fe),lw=2)\n",
    "axes[2,1].set_ylim(0,7.5)\n",
    "axes[2,1].set_xlim(-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(12, 12), dpi=120,sharey=True)\n",
    "# 00\n",
    "axes[0,0].set_title(\"Global Alignment\",fontsize=16)\n",
    "axes[0,0].set_ylabel(\"LD 2\",fontsize=16)\n",
    "axes[0,0].tick_params(axis='both',labelsize=16)\n",
    "axes[0,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(global_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "axes[0,0].contour(xx,yy,H,cmap='binary')\n",
    "axes[0,0].scatter(y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes[0,0].set_xlim(-10,5)\n",
    "#01\n",
    "axes[0,1].set_title(\"Alignment to Cluster 1\",fontsize=16)\n",
    "axes[0,1].tick_params(axis='both',labelsize=16)\n",
    "axes[0,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(cluster_1_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "axes[0,1].contour(xx,yy,H,cmap='binary')\n",
    "axes[0,1].scatter(y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes[0,1].set_xlim(-5,10)\n",
    "#10\n",
    "axes[1,0].set_title(\"Alignment to Cluster 2\",fontsize=16)\n",
    "axes[1,0].set_ylabel(\"LD 2\",fontsize=16)\n",
    "axes[1,0].tick_params(axis='both',labelsize=16)\n",
    "axes[1,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(cluster_2_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "axes[1,0].contour(xx,yy,H,cmap='binary')\n",
    "axes[1,0].scatter(y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes[1,0].set_xlim(-10,5)\n",
    "# 11\n",
    "axes[1,1].set_title(\"Alignment to Cluster 3\",fontsize=16)\n",
    "axes[1,1].tick_params(axis='both',labelsize=16)\n",
    "axes[1,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(cluster_3_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "axes[1,1].contour(xx,yy,H,cmap='binary')\n",
    "axes[1,1].scatter(y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes[1,1].set_xlim(-5,10)\n",
    "#20\n",
    "axes[2,0].set_title(\"Alignment to Cluster 4\",fontsize=16)\n",
    "axes[2,0].set_ylabel(\"LD 2\",fontsize=16)\n",
    "axes[2,0].set_xlabel(\"LD 1\",fontsize=16)\n",
    "axes[2,0].tick_params(axis='both',labelsize=16)\n",
    "axes[2,0].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(cluster_4_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "axes[2,0].contour(xx,yy,H,cmap='binary')\n",
    "axes[2,0].scatter(y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes[2,0].set_xlim(-10,5)\n",
    "# 21\n",
    "axes[2,1].set_title(\"Alignment to Cluster 5\",fontsize=16)\n",
    "axes[2,1].set_xlabel(\"LD 1\",fontsize=16)\n",
    "axes[2,1].tick_params(axis='both',labelsize=16)\n",
    "axes[2,1].grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(cluster_5_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(-xcenters, ycenters)\n",
    "axes[2,1].contour(xx,yy,H,cmap='binary')\n",
    "axes[2,1].scatter(-y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes[2,1].set_xlim(-5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(5.25, 5.25), dpi=120,sharey=True)\n",
    "axes.set_title(\"Alignment to Cluster 1\",fontsize=12)\n",
    "axes.tick_params(axis='both',labelsize=12)\n",
    "axes.grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "y_pred = lda.fit_transform(cluster_1_aligned_traj.reshape(coord.trajectory.n_frames, CAatomSel.n_atoms*3), clusters)\n",
    "x = y_pred[:,0]\n",
    "y = y_pred[:,1]\n",
    "H, xedges, yedges = np.histogram2d(x,y,bins=40,density=True)\n",
    "xcenters = (xedges[:-1] + xedges[1:]) / 2\n",
    "ycenters = (yedges[:-1] + yedges[1:]) / 2\n",
    "H = -np.log(H.T)\n",
    "xx, yy = np.meshgrid(xcenters, ycenters)\n",
    "axes.contour(xx,yy,H,cmap='binary')\n",
    "axes.scatter(y_pred[:,0],y_pred[:,1],c=clusters)\n",
    "axes.set_xlim(-5,10)\n",
    "axes.set_ylabel(\"LD 2\",fontsize=12)\n",
    "axes.set_xlabel(\"LD 1\",fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(7.25, 5.25), dpi=120,sharey=True)\n",
    "axes.set_title(\"5-state WSGMM Cluster ID Traj\",fontsize=12)\n",
    "axes.tick_params(axis='both',labelsize=12)\n",
    "axes.grid(b=True, which='major', axis='both', color='#808080', linestyle='--')\n",
    "time = np.arange(0,clusters.size,1)*0.001\n",
    "axes.scatter(time,clusters,c=clusters)\n",
    "axes.set_xlabel(\"Simulation Time ($\\mu$s)\",fontsize=12)\n",
    "axes.set_ylabel(\"Cluster ID\",fontsize=12)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Cluster Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_kabsch_rotation_matrix(mobile, target, weights):\n",
    "    correlation_matrix = np.dot(np.transpose(mobile), np.dot(weights, target))\n",
    "    V, S, W_tr = np.linalg.svd(correlation_matrix)\n",
    "    if np.linalg.det(V) * np.linalg.det(W_tr) < 0.0:\n",
    "        V[:, -1] = -V[:, -1]\n",
    "    rotation = np.dot(V, W_tr)\n",
    "    #mobile_prime = np.dot(mobile,rotation)\n",
    "    return rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in Trp-cage trajectory data again but this time also load all atoms\n",
    "prmtopFileName = \"trp-cage-2jof_350K.run.3650000000.part0146.nowater.gro\"\n",
    "trajFileName = \"trp-cage-2jof_350K.stepid10150000000.every1ns.nowater.align.xtc\"\n",
    "\n",
    "coord = md.Universe(prmtopFileName,trajFileName)\n",
    "\n",
    "print(\"Number of atoms in trajectory:\", coord.atoms.n_atoms)\n",
    "print(\"Number of frames in trajectory:\", coord.trajectory.n_frames)\n",
    "# make atom selection\n",
    "CAatomSel = coord.select_atoms('name CA')\n",
    "print(\"Number of atoms in CA selection:\", CAatomSel.n_atoms)\n",
    "allSel = coord.select_atoms('all')\n",
    "print(\"Number of atoms in all selection:\", allSel.n_atoms)\n",
    "# create traj data of selection\n",
    "ca_traj_data = np.empty((coord.trajectory.n_frames,CAatomSel.n_atoms,3),dtype=float)\n",
    "all_traj_data = np.empty((coord.trajectory.n_frames,allSel.n_atoms,3),dtype=float)\n",
    "\n",
    "#loop traj\n",
    "for ts in coord.trajectory:\n",
    "    ca_traj_data[ts.frame,:,:] = CAatomSel.positions - CAatomSel.center_of_geometry()\n",
    "    all_traj_data[ts.frame,:,:] = allSel.positions - CAatomSel.center_of_geometry()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform uniform alignment of averages for ease of subsequent visualization/comparison\n",
    "global_avg, cluster_avgs = traj_tools.traj_iterative_average(wsgmm.centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save PDB structures of cluster centers (will only be CA atoms)\n",
    "for i in range(n_clusters):\n",
    "    with md.Writer(\"trpcage\" + '_cluster{}_center.pdb'.format(i+1),CAatomSel.n_atoms) as W:\n",
    "        CAatomSel.positions = cluster_avgs[i]\n",
    "        W.write(CAatomSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random \n",
    "from random import sample\n",
    "# set number of random frames\n",
    "nRandomFrames = 100\n",
    "traj_data_rand = np.empty((nRandomFrames,allSel.n_atoms,3),dtype=np.float64)\n",
    "for i in range(n_clusters):\n",
    "    indeces = np.argwhere(clusters==i).flatten()\n",
    "    # choose nRandomFrames random integers between 0 and cluster_pop\n",
    "    random_frames = sample(list(indeces),nRandomFrames)\n",
    "    for j, frame in enumerate(random_frames):\n",
    "        # determine rotation matrix based on weighted rotation of CA atoms\n",
    "        rotation_matrix = weight_kabsch_rotation_matrix(ca_traj_data[frame],cluster_avgs[i],wsgmm.precisions[i])\n",
    "        # rotate all atoms\n",
    "        traj_data_rand[j] = np.dot(all_traj_data[frame],rotation_matrix)\n",
    "    with md.Writer(\"trpcage\" + '_cluster{}_100_random_frames.dcd'.format(i+1),allSel.n_atoms) as W:\n",
    "        for j in range(nRandomFrames):\n",
    "            allSel.positions = traj_data_rand[j]\n",
    "            W.write(allSel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
